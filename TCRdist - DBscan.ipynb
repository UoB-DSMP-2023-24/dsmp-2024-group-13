{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ada53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/2213001380.py:6: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(path2, sep='\\t')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Missing Values': cdr3.alpha         5559\n",
       " v.alpha            5585\n",
       " j.alpha            5740\n",
       " cdr3.beta           925\n",
       " v.beta              921\n",
       " d.beta             8374\n",
       " j.beta              996\n",
       " species               0\n",
       " mhc.a                 0\n",
       " mhc.b                 0\n",
       " antigen.gene         31\n",
       " antigen.epitope       0\n",
       " vdjdb.score           0\n",
       " mhc.class             0\n",
       " dtype: int64,\n",
       " 'Missing Values df_cleaned': cdr3.alpha            0\n",
       " v.alpha               0\n",
       " j.alpha             122\n",
       " cdr3.beta             0\n",
       " v.beta                0\n",
       " d.beta             2656\n",
       " j.beta               74\n",
       " species               0\n",
       " mhc.a                 0\n",
       " mhc.b                 0\n",
       " antigen.gene         31\n",
       " antigen.epitope       0\n",
       " vdjdb.score           0\n",
       " mhc.class             0\n",
       " dtype: int64}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "path2 =  \"/Users/tomelder/Downloads/vdjdb-2023-06-01/vdjdb_full.txt\"\n",
    "data = pd.read_csv(path2, sep='\\t')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df[(df['vdjdb.score'] == 2) | (df['vdjdb.score'] == 3) | (df['vdjdb.score'] == 4)  | (df['vdjdb.score'] == 1) ]\n",
    "\n",
    "relevant_columns = [\n",
    "    'cdr3.alpha', 'v.alpha', 'j.alpha', 'cdr3.beta', 'v.beta', 'd.beta', 'j.beta',\n",
    "    'species', 'mhc.a', 'mhc.b', 'antigen.gene','antigen.epitope', 'vdjdb.score', 'mhc.class'\n",
    "]\n",
    "# For the purpose of this example, we won't filter out lower-quality scores to avoid data imbalance,\n",
    "# but in practice, you may want to consider this based on the dataset's size and distribution.\n",
    "filtered_data = df[relevant_columns]\n",
    "# Displaying the first few rows of the filtered dataset to verify the selection\n",
    "filtered_data\n",
    "# Checking for missing values in crucial columns\n",
    "missing_values = filtered_data.isnull().sum()\n",
    "\n",
    "# Examining the number of unique values in categorical columns for potential encoding strategies\n",
    "unique_values = filtered_data.nunique()\n",
    "\n",
    "# Removing rows with missing cdr3 sequences\n",
    "df_cleaned = filtered_data.dropna(subset=['cdr3.alpha','cdr3.beta'])\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "missing_values_df_cleaned = df_cleaned.isnull().sum()\n",
    "report = {\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Missing Values df_cleaned\": missing_values_df_cleaned\n",
    "}\n",
    "\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1e3593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter lower bound for cdr3.alpha length: 10\n",
      "Enter upper bound for cdr3.alpha length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/163780384.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name + '.length'] = df[column_name].apply(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter lower bound for cdr3.beta length: 10\n",
      "Enter upper bound for cdr3.beta length: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/163780384.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name + '.length'] = df[column_name].apply(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter lower bound for antigen.epitope length: 0\n",
      "Enter upper bound for antigen.epitope length: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/163780384.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column_name + '.length'] = df[column_name].apply(len)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the minimum score (inclusive) for vdjdb.score: 1\n",
      "Enter the species to filter by (separated by commas): HomoSapiens\n"
     ]
    }
   ],
   "source": [
    "def filter_by_length_range(df, column_name):\n",
    "    \"\"\"\n",
    "    Asks the user for length bounds and filters the DataFrame to include rows where the length of\n",
    "    the specified column's sequence falls within the provided bounds.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The data frame to filter.\n",
    "    column_name (str): The name of the sequence column to check (e.g., 'cdr3.alpha').\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame filtered by the specified length range.\n",
    "    \"\"\"\n",
    "    # Ask the user for length bounds\n",
    "    lower_bound = int(input(f\"Enter lower bound for {column_name} length: \"))\n",
    "    upper_bound = int(input(f\"Enter upper bound for {column_name} length: \"))\n",
    "    \n",
    "    # Calculate the sequence lengths\n",
    "    df[column_name + '.length'] = df[column_name].apply(len)\n",
    "    \n",
    "    # Filter based on the length range\n",
    "    return df[(df[column_name + '.length'] >= lower_bound) & (df[column_name + '.length'] <= upper_bound)]\n",
    "\n",
    "def filter_by_species(df):\n",
    "    \"\"\"\n",
    "    Asks the user for species to filter by and filters the DataFrame to include rows where the\n",
    "    species column matches any of the species provided.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The data frame to filter.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame filtered by the specified species.\n",
    "    \"\"\"\n",
    "    # Ask the user for species to filter by\n",
    "    input_species = input(\"Enter the species to filter by (separated by commas): \")\n",
    "    species_to_filter = [species.strip() for species in input_species.split(',')]\n",
    "    \n",
    "    return df[df['species'].isin(species_to_filter)]\n",
    "\n",
    "\n",
    "def filter_by_minimum_score(df, column='vdjdb.score'):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame based on a minimum score inputted by the user for a specified column.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The data frame to filter.\n",
    "    column (str): The name of the column to apply the filter on. Defaults to 'vdjdb.score'.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A DataFrame filtered based on the user-specified minimum score.\n",
    "    \"\"\"\n",
    "    # Prompting user for minimum score\n",
    "    min_score = input(f\"Enter the minimum score (inclusive) for {column}: \")\n",
    "    \n",
    "    # Validating user input\n",
    "    try:\n",
    "        min_score = int(min_score)\n",
    "        if min_score < 0 or min_score > 3:\n",
    "            print(\"Score out of range. Please enter a value between 0 and 3.\")\n",
    "            return df\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter an integer value.\")\n",
    "        return df\n",
    "    \n",
    "    # Filtering the DataFrame\n",
    "    filtered_df = df[df[column] >= min_score]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "def filter_by_mhc_class(df, column='mhc.class'):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame based on a user-specified MHC class ('MHCI' or 'MHCII').\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The data frame to filter.\n",
    "    column (str): The name of the column to apply the filter on. Defaults to 'mhc.class'.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: A DataFrame filtered based on the user-specified MHC class.\n",
    "    \"\"\"\n",
    "    # Prompting user for MHC class\n",
    "    mhc_class = input(f\"Enter the MHC class to keep ('MHCI' or 'MHCII'): \").strip()\n",
    "\n",
    "    # Validating user input\n",
    "    if mhc_class not in ['MHCI', 'MHCII']:\n",
    "        print(\"Invalid input. Please enter 'MHCI' or 'MHCII'.\")\n",
    "        return df\n",
    "    \n",
    "    # Filtering the DataFrame\n",
    "    filtered_df = df[df[column] == mhc_class]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = df_cleaned\n",
    "# Apply length range filters\n",
    "df_filtered_alpha = filter_by_length_range(df, 'cdr3.alpha')\n",
    "df_filtered_beta = filter_by_length_range(df, 'cdr3.beta')\n",
    "df_filtered_epitope = filter_by_length_range(df, 'antigen.epitope')\n",
    "df_filtered_min_score = filter_by_minimum_score(df)\n",
    "# Intersect the filtered DataFrames to get only rows that meet all criteria\n",
    "df_length_filtered = df_filtered_alpha.merge(df_filtered_beta).merge(df_filtered_epitope)\n",
    "\n",
    "# Further filter by species\n",
    "df_final_filtered = filter_by_species(df_length_filtered)\n",
    "\n",
    "# df_final_filtered is now your preprocessed DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31ec6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdr3.alpha                0\n",
      "v.alpha                   0\n",
      "cdr3.beta                 0\n",
      "v.beta                    0\n",
      "j.beta                    0\n",
      "species                   0\n",
      "mhc.a                     0\n",
      "mhc.b                     0\n",
      "antigen.gene              0\n",
      "antigen.epitope           0\n",
      "vdjdb.score               0\n",
      "mhc.class                 0\n",
      "cdr3.alpha.length         0\n",
      "cdr3.beta.length          0\n",
      "antigen.epitope.length    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/3232855618.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_filtered.drop(['j.alpha'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_final_filtered\n",
    "\n",
    "df_final_filtered.drop(['d.beta'], axis=1, inplace=True)\n",
    "\n",
    "df_final_filtered.drop(['j.alpha'], axis=1, inplace=True)\n",
    "\n",
    "print(df_final_filtered.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f19ba6",
   "metadata": {},
   "source": [
    "# CDR3 seq TCRdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05066483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "Requirement already satisfied: tcrdist3==0.2.2 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (0.2.2)\n",
      "Requirement already satisfied: zipdist>=0.1.5 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.1.5)\n",
      "Requirement already satisfied: tcrsampler>=0.1.9 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.1.9)\n",
      "Requirement already satisfied: numba in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.54.1)\n",
      "Requirement already satisfied: palmotif>=0.2 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.7.1)\n",
      "Requirement already satisfied: fishersapi in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.5)\n",
      "Requirement already satisfied: dill>=0.3.2 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.3.8)\n",
      "Requirement already satisfied: olga>=1.2.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.2.4)\n",
      "Requirement already satisfied: pwseqdist>=0.6 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.6)\n",
      "Requirement already satisfied: numpy>=1.16.4 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.26.4)\n",
      "Requirement already satisfied: hierdiff>=0.4 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (0.9)\n",
      "Requirement already satisfied: parasail>=1.1.17 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.3.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.5.3)\n",
      "Requirement already satisfied: parmap>=1.5.2 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrdist3==0.2.2) (1.7.0)\n",
      "Requirement already satisfied: joblib>=0.16 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from hierdiff>=0.4->tcrdist3==0.2.2) (1.1.0)\n",
      "Requirement already satisfied: jinja2>=2.10.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from hierdiff>=0.4->tcrdist3==0.2.2) (2.11.3)\n",
      "Requirement already satisfied: statsmodels>=0.10 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from hierdiff>=0.4->tcrdist3==0.2.2) (0.12.2)\n",
      "Requirement already satisfied: fisher in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from fishersapi->tcrdist3==0.2.2) (0.1.14)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from jinja2>=2.10.1->hierdiff>=0.4->tcrdist3==0.2.2) (1.1.1)\n",
      "Requirement already satisfied: matplotlib in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from palmotif>=0.2->tcrdist3==0.2.2) (3.4.3)\n",
      "Requirement already satisfied: svgwrite in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from palmotif>=0.2->tcrdist3==0.2.2) (1.4.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->tcrdist3==0.2.2) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from pandas>=0.24.2->tcrdist3==0.2.2) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=0.24.2->tcrdist3==0.2.2) (1.16.0)\n",
      "Collecting numpy>=1.16.4\n",
      "  Using cached numpy-1.22.4-cp39-cp39-macosx_10_15_x86_64.whl (17.7 MB)\n",
      "Requirement already satisfied: patsy>=0.5 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.10->hierdiff>=0.4->tcrdist3==0.2.2) (0.5.2)\n",
      "Requirement already satisfied: progress>=1.5 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from tcrsampler>=0.1.9->tcrdist3==0.2.2) (1.6)\n",
      "Requirement already satisfied: feather-format>=0.4.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from zipdist>=0.1.5->tcrdist3==0.2.2) (0.4.1)\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from feather-format>=0.4.1->zipdist>=0.1.5->tcrdist3==0.2.2) (15.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->palmotif>=0.2->tcrdist3==0.2.2) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->palmotif>=0.2->tcrdist3==0.2.2) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->palmotif>=0.2->tcrdist3==0.2.2) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from matplotlib->palmotif>=0.2->tcrdist3==0.2.2) (3.0.4)\n",
      "  Using cached numpy-1.20.3-cp39-cp39-macosx_10_9_x86_64.whl (16.1 MB)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from numba->tcrdist3==0.2.2) (0.37.0)\n",
      "Requirement already satisfied: setuptools in /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages (from numba->tcrdist3==0.2.2) (58.0.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "xarray 2023.8.0 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\n",
      "tensorflow 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 1.20.3 which is incompatible.\n",
      "cartopy 0.22.0 requires numpy>=1.21, but you have numpy 1.20.3 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.20.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow (/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tcrdist3==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e352dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/wiraninha_sampler.zip https://www.dropbox.com/s/ily0td3tn1uc7bi/wiraninha_sampler.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    66    0    66    0     0    122      0 --:--:-- --:--:-- --:--:--   122\n",
      "100   320  100   320    0     0    277      0  0:00:01  0:00:01 --:--:--   277\n",
      "100 6882k  100 6882k    0     0  2237k      0  0:00:03  0:00:03 --:--:-- 5306k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/wirasinha_mouse_alpha_g8a.tsv.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/wiraninha_sampler.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ravens_samplers.zip https://www.dropbox.com/s/bahxa6x86drq0n5/ravens_samplers.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    64    0    64    0     0    198      0 --:--:-- --:--:-- --:--:--   198\n",
      "100   320  100   320    0     0    269      0  0:00:01  0:00:01 --:--:--     0\n",
      "100  313k  100  313k    0     0   158k      0  0:00:01  0:00:01 --:--:--  558k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ravens_human_gamma_t.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ravens_samplers.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/olga_sampler.zip https://www.dropbox.com/s/qlsxvst8bn04l0n/olga_sampler.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    61    0    61    0     0    166      0 --:--:-- --:--:-- --:--:--   166\n",
      "100   320  100   320    0     0    241      0  0:00:01  0:00:01 --:--:--     0\n",
      "100 23.5M  100 23.5M    0     0  3886k      0  0:00:06  0:00:06 --:--:-- 6506k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/olga_human_beta_t.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/olga_sampler.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_mouse_sampler.zip https://www.dropbox.com/s/yz8v1c1gf2eyzxk/ruggiero_mouse_sampler.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    71    0    71    0     0     85      0 --:--:-- --:--:-- --:--:--    85\n",
      "100   320  100   320    0     0    244      0  0:00:01  0:00:01 --:--:--     0\n",
      "100  210k  100  210k    0     0    98k      0  0:00:02  0:00:02 --:--:-- 2416k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_mouse_alpha_t.tsv.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_mouse_sampler.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_human_sampler.zip https://www.dropbox.com/s/jda6qtemk65zlfk/ruggiero_human_sampler.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    71    0    71    0     0    238      0 --:--:-- --:--:-- --:--:--   239\n",
      "100   320  100   320    0     0    393      0 --:--:-- --:--:-- --:--:--   393\n",
      "100  599k  100  599k    0     0   418k      0  0:00:01  0:00:01 --:--:--  984k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_human_alpha_t.tsv.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/ruggiero_human_sampler.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/emerson_human_beta_t_cmvneg.tsv.sampler.tsv.zip https://www.dropbox.com/s/04mxrzw7f5wkg1x/emerson_human_beta_t_cmvneg.tsv.sampler.tsv.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    92    0    92    0     0    264      0 --:--:-- --:--:-- --:--:--   264\n",
      "100   320  100   320    0     0    385      0 --:--:-- --:--:-- --:--:--   385\n",
      "100 11.3M  100 11.3M    0     0  3838k      0  0:00:03  0:00:03 --:--:-- 7236k\n",
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/emerson_human_beta_t_cmvneg.tsv.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/emerson_human_beta_t_cmvneg.tsv.sampler.tsv.zip\n",
      "RUNNING: curl -o /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/britanova_human_beta_t_cb.tsv.sampler.tsv.zip https://www.dropbox.com/s/87n5v2by80xhy1q/britanova_human_beta_t_cb.tsv.sampler.tsv.zip?dl=1 -L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100    90    0    90    0     0    263      0 --:--:-- --:--:-- --:--:--   263\n",
      "100   320  100   320    0     0    364      0 --:--:-- --:--:-- --:--:--   364\n",
      "100 28.3M  100 28.3M    0     0  5736k      0  0:00:05  0:00:05 --:--:-- 8742k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/britanova_human_beta_t_cb.tsv.sampler.tsv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "replace /Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrsampler/db/britanova_human_beta_t_cb.tsv.sampler.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n",
      "(EOF or read error, treating as \"[N]one\" ...)\n",
      "/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n",
      "/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/base/tsa_model.py:7: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (to_datetime, Int64Index, DatetimeIndex, Period,\n"
     ]
    }
   ],
   "source": [
    "from tcrsampler.setup_db import install_all_next_gen\n",
    "install_all_next_gen(dry_run = False)\n",
    "from tcrdist.rep_funcs import _pws, _pw  \n",
    "from tcrdist.repertoire import TCRrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b9ea94",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/2049687273.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_filtered.rename(columns={'cdr3.alpha': 'cdr3_a_aa', 'cdr3.beta': 'cdr3_b_aa', 'v.alpha':'v_a_gene','j.alpha': 'j_a_gene','v.beta': 'v_b_gene','j.beta': 'j_b_gene','antigen.epitope':'epitope'}, inplace=True)\n",
      "/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrdist/repertoire.py:159: UserWarning: cell_df needs a counts column to track clonal number of frequency\n",
      "\n",
      "  self._validate_cell_df()\n",
      "/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrdist/repertoire.py:791: UserWarning: No 'count' column provided; count column set to 1\n",
      "  warnings.warn(\"No 'count' column provided; count column set to 1\")\n",
      "/Users/tomelder/opt/anaconda3/lib/python3.9/site-packages/tcrdist/repertoire.py:792: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.cell_df['count'] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 15)\n",
      "[[ 0 24 24 ... 23 23 23]\n",
      " [24  0  0 ... 20 20 20]\n",
      " [24  0  0 ... 20 20 20]\n",
      " ...\n",
      " [23 20 20 ...  0  0  4]\n",
      " [23 20 20 ...  0  0  4]\n",
      " [23 20 20 ...  4  4  0]]\n",
      "(182, 182)\n"
     ]
    }
   ],
   "source": [
    "df_final_filtered.rename(columns={'cdr3.alpha': 'cdr3_a_aa', 'cdr3.beta': 'cdr3_b_aa', 'v.alpha':'v_a_gene','j.alpha': 'j_a_gene','v.beta': 'v_b_gene','j.beta': 'j_b_gene','antigen.epitope':'epitope'}, inplace=True)\n",
    "\n",
    "print(np.shape(df_final_filtered))\n",
    "def cdr3plot2(df_):\n",
    "    # Assuming TCRrep is correctly set up to work with the provided dataframe\n",
    "    tr_vdjdb = TCRrep(cell_df=df_, \n",
    "                      organism='human',\n",
    "                      chains=['beta', 'alpha'],\n",
    "                      deduplicate=False,\n",
    "                      compute_distances=True )\n",
    "    \n",
    "    tcrdist_matrix = tr_vdjdb.pw_cdr3_b_aa\n",
    "    return tcrdist_matrix\n",
    "\n",
    "tcrdist_matrix =  cdr3plot2(df_final_filtered)\n",
    "print(tcrdist_matrix)\n",
    "print(np.shape(tcrdist_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcefd67",
   "metadata": {},
   "source": [
    "### DBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5a609ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of DBscan clusters: 11\n",
      "Number of true clusters: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dg/1nsyrpm96v149hfhy4g6qc0h0000gn/T/ipykernel_53926/1066954043.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final_filtered['cluster'] = clusters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(metric='precomputed', eps=0.2, min_samples=2)  # Example: eps value here is hypothetical\n",
    "clusters = dbscan.fit_predict(tcrdist_matrix)\n",
    "\n",
    "# Adding cluster labels to your data (assuming you have a DataFrame 'df' with your TCR sequence data)\n",
    "df_final_filtered['cluster'] = clusters\n",
    "\n",
    "df_final_filtered\n",
    "\n",
    "# Exclude outlier points and count unique clusters\n",
    "n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)\n",
    "\n",
    "print(f\"Number of DBscan clusters: {n_clusters}\")\n",
    "\n",
    "print(f\"Number of true clusters: {len(df_final_filtered['epitope'].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daec8d7",
   "metadata": {},
   "source": [
    "### Random classifier for baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb7ac75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_clustering(df, n_clusters):\n",
    "    \"\"\"Assigns each row in the dataframe to a random cluster.\"\"\"\n",
    "    random_clusters = np.random.randint(0, n_clusters, len(df))\n",
    "    df['random_cluster'] = random_clusters\n",
    "    return df\n",
    "\n",
    "def calculate_random_purity(df):\n",
    "    purity_sum = 0\n",
    "    for cluster in df['random_cluster'].unique():\n",
    "        cluster_df = df[df['random_cluster'] == cluster]\n",
    "        most_common_epitope = cluster_df['epitope'].value_counts().idxmax()\n",
    "        purity_sum += cluster_df['epitope'].value_counts().max() / len(cluster_df)\n",
    "    purity = purity_sum / len(df['random_cluster'].unique())\n",
    "    return purity\n",
    "\n",
    "def calculate_random_consistency(df, epitope_clusters):\n",
    "    correct_assignments = 0\n",
    "    for epitope, cluster in epitope_clusters.items():\n",
    "        correct_assignments += len(df[(df['epitope'] == epitope) & (df['random_cluster'] == cluster)])\n",
    "    consistency = correct_assignments / len(df)\n",
    "    return consistency\n",
    "\n",
    "def simulate_baseline(df, n_clusters, iterations=50):\n",
    "    purity_scores = []\n",
    "    consistency_scores = []\n",
    "    def get_epitope_clusters(df):\n",
    "        epitope_clusters = {}\n",
    "        for epitope in df['epitope'].unique():\n",
    "            epitope_df = df[df['epitope'] == epitope]\n",
    "            most_common_cluster = epitope_df['cluster'].value_counts().idxmax()\n",
    "            epitope_clusters[epitope] = most_common_cluster\n",
    "        return epitope_clusters\n",
    "\n",
    "    # Assuming df_final_filtered has 'cluster' column from DBSCAN and 'epitope' information\n",
    "    epitope_clusters = get_epitope_clusters(df_final_filtered)\n",
    "\n",
    "  # This should come from your actual clustering method\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        df_random = random_clustering(df.copy(), n_clusters)\n",
    "        purity = calculate_random_purity(df_random)\n",
    "        consistency = calculate_random_consistency(df_random, epitope_clusters)\n",
    "        \n",
    "        purity_scores.append(purity)\n",
    "        consistency_scores.append(consistency)\n",
    "    \n",
    "    return np.mean(purity_scores), np.mean(consistency_scores)\n",
    "\n",
    "pur_base, consist_base = simulate_baseline(df_final_filtered, n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05b16cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retention: 0.7252747252747253\n",
      "Purity: 0.9444444444444445\n",
      "Consistency: 0.9318181818181818\n",
      "Purity base: 0.37189435326019654\n",
      "Consistency base: 0.0687912087912088\n"
     ]
    }
   ],
   "source": [
    "def calculate_retention(df):\n",
    "    # Retention is the fraction of TCR sequences assigned to any cluster\n",
    "    assigned = df[df['cluster'] != -1]  # DBSCAN labels outliers as -1\n",
    "    retention = len(assigned) / len(df)\n",
    "    return retention\n",
    "\n",
    "def calculate_purity(df):\n",
    "    # Purity is defined for each cluster, then averaged across clusters\n",
    "    purity_sum = 0\n",
    "    for cluster in df['cluster'].unique():\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_df = df[df['cluster'] == cluster]\n",
    "        most_common_epitope = cluster_df['epitope'].value_counts().idxmax()\n",
    "        purity_sum += cluster_df['epitope'].value_counts().max() / len(cluster_df)\n",
    "    purity = purity_sum / (len(df['cluster'].unique()) - (1 if -1 in df['cluster'].unique() else 0))\n",
    "    return purity\n",
    "\n",
    "def calculate_consistency(df):\n",
    "    # Consistency is calculated based on the assignment of TCR sequences to the \"true\" cluster for their epitope\n",
    "    epitope_clusters = {}\n",
    "    for epitope in df['epitope'].unique():\n",
    "        epitope_df = df[df['epitope'] == epitope]\n",
    "        most_common_cluster = epitope_df['cluster'].value_counts().idxmax()\n",
    "        epitope_clusters[epitope] = most_common_cluster\n",
    "\n",
    "    correct_assignments = 0\n",
    "    for epitope, cluster in epitope_clusters.items():\n",
    "        correct_assignments += len(df[(df['epitope'] == epitope) & (df['cluster'] == cluster)])\n",
    "\n",
    "    consistency = correct_assignments / len(df[df['cluster'] != -1])\n",
    "    return consistency\n",
    "\n",
    "\n",
    "\n",
    "retention = calculate_retention(df_final_filtered)\n",
    "purity = calculate_purity(df_final_filtered)\n",
    "consistency = calculate_consistency(df_final_filtered)\n",
    "\n",
    "print(f\"Retention: {retention}\")\n",
    "print(f\"Purity: {purity}\")\n",
    "print(f\"Consistency: {consistency}\")\n",
    "\n",
    "print(f\"Purity base: {pur_base}\")\n",
    "print(f\"Consistency base: {consist_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0035a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
