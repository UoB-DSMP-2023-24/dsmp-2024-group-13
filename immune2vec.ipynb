{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Immune2vec: Embedding B/T Cell Receptor Sequences Using Natural Language Processing**\n",
    "\n",
    "In NLP, the term “embedding” refers to the representation of symbolic information in text at the word-level, phrase-level, and even sentence-level, in terms of real number vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Data set\n",
    "\n",
    "The first step in creating the model is building an adequate corpus for word2vec training. All scores of over 0, alpha and beta cdr3 sequences between length 12 and 14, species type HomoSapien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Christian Gauthier\\AppData\\Local\\Temp\\ipykernel_21636\\1357857951.py:2: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, delimiter='\\t')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9300, 6)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"vdjdb_full.txt\"\n",
    "df = pd.read_csv(file_path, delimiter='\\t')\n",
    "df = df.drop_duplicates()\n",
    "df = df[(df['vdjdb.score'] > 0)]\n",
    "df = df[['cdr3.alpha','cdr3.beta','species','antigen.epitope','antigen.gene','vdjdb.score']]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cdr3.alpha.length'] = df['cdr3.alpha'].apply(lambda x: len(x) if pd.notnull(x) and not isinstance(x, float) else 0)\n",
    "df = df[(df['cdr3.alpha.length'] >= 12) & (df['cdr3.alpha.length'] <= 14)]\n",
    "\n",
    "df['cdr3.beta.length'] = df['cdr3.beta'].apply(lambda x: len(x) if pd.notnull(x) and not isinstance(x, float) else 0)\n",
    "df = df[(df['cdr3.beta.length'] >= 12) & (df['cdr3.beta.length'] <= 14)]\n",
    "\n",
    "df = df[df['species'] == 'HomoSapiens']\n",
    "\n",
    "df['cdr3combined'] = df['cdr3.alpha'].fillna('') + df['cdr3.beta'].fillna('')\n",
    "\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdr3.alpha                         CAYRPPGTYKYIF\n",
      "cdr3.beta                         CASSALASLNEQFF\n",
      "species                              HomoSapiens\n",
      "antigen.epitope                         FLKEKGGL\n",
      "antigen.gene                                 Nef\n",
      "vdjdb.score                                    2\n",
      "cdr3.alpha.length                             13\n",
      "cdr3.beta.length                              14\n",
      "cdr3combined         CAYRPPGTYKYIFCASSALASLNEQFF\n",
      "Name: 0, dtype: object\n",
      "(555, 9)\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocess CDR3 sequences and translate to amino acids**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.527027027027027\n",
      "Test accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df['cdr3combined'] = df['cdr3combined'].apply(lambda x: x.split())\n",
    "\n",
    "model = Word2Vec(df['cdr3combined'], min_count=1)\n",
    "\n",
    "df['cdr3combined_vec'] = df['cdr3combined'].apply(lambda x: np.mean([model.wv[word] for word in x], axis=0))\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df['antigen.epitope'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cdr3combined_vec'].tolist(), labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", clf.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", clf.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
